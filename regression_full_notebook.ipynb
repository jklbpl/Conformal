{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2728e5",
   "metadata": {},
   "source": [
    "## Conformal learning from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4313d4f9",
   "metadata": {},
   "source": [
    "Conformal learning is a framework that allows constructing predictions with predefined accuracy guarantees for *iid* data. It can be used on top of any traditional predictive algorithm for both classification and regression. The theory behind conformal learning might seem complicated, but it is based on a simple idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd67757",
   "metadata": {},
   "source": [
    "The goal of this notebook is to guide you through the theory of conformal regressors.\n",
    "\n",
    "We will build a conformal regressors step-by-step explaining the required background on the way. In the end, we will confirm that the constructed model gives the same results as the code from nonconformist library.\n",
    "\n",
    "We will be working with the Inductive Conformal Prediction (ICP) framework, because conformal regressor has no transductive algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2aa290",
   "metadata": {},
   "source": [
    "Very first step: importing required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f528b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import load_diabetes\n",
    "from nonconformist.cp import IcpRegressor\n",
    "from nonconformist.nc import NcFactory\n",
    "from nonconformist.nc import SignErrorErrFunc\n",
    "from nonconformist.nc import AbsErrorErrFunc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9f3d8",
   "metadata": {},
   "source": [
    "For demonstration, we will use a California Housing dataset from [sklearn library](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) .\n",
    "\n",
    "For future computatuion we should split the data into fractions - training and test sets. Additionaly, training data will be splitted into training and calibration sets. But for current section we will use only test and training sets. Calibration one will be used in the next sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47cad707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 2064\n",
      "Calibration size: 2000\n",
      "Train size: 16576\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_data, data_target = fetch_california_housing(return_X_y= True)\n",
    "\n",
    "df_features = pd.DataFrame(data_data)\n",
    "df_target = pd.DataFrame(data_target)\n",
    "idx_size = df_target.size\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "idx = np.random.permutation(len(data_data))\n",
    "\n",
    "# test = 10%, test(test+calib) = 90% \n",
    "test_size = int(idx_size*0.1)\n",
    "train_size = idx_size-test_size\n",
    "calib_size = 2000\n",
    "train_size = train_size - calib_size\n",
    "\n",
    "idx_train, idx_cal, idx_test = idx[:train_size], idx[train_size:train_size + calib_size], idx[train_size + calib_size:]\n",
    "\n",
    "\n",
    "print('Test size: {}'.format(test_size))\n",
    "print('Calibration size: {}'.format(calib_size))\n",
    "print('Train size: {}'.format(train_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9accc",
   "metadata": {},
   "source": [
    "After splitting the data we need to feed the model with training data. For our example *Random Forest Regressor* was chosen. After our model ate some data-food we can start generating predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e180a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(data_data[idx_train, :], data_target[idx_train])\n",
    "predictions_cal = model.predict(data_data[idx_cal,:])\n",
    "predictions_test = model.predict(data_data[idx_test,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85091e0",
   "metadata": {},
   "source": [
    "A **nonconformity** functions are used to measure the nonconformity or strageness of the data point. For regression example there're two: absolute error function and signed error function __where to refer to?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b66546b",
   "metadata": {},
   "source": [
    "### Definition of the absolute srror function: \n",
    "\n",
    "$\\alpha_i = \\left| y_i - \\hat{y}_i \\right| $\n",
    "\n",
    "Second function is used to form the borders for conformal regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6267e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abserror(prediction_set, y):\n",
    "    return np.abs(prediction_set - y)\n",
    "\n",
    "\n",
    "def abs_err_inv(cal_score, significance,method):\n",
    "    cal_scores_sorted = np.sort(cal_score)[::-1]\n",
    "    border = (1-significance)*((len(cal_scores_sorted)+1)/len(cal_scores_sorted))\n",
    "    #border = 1 - significance\n",
    "    quantile_significance = np.quantile(cal_scores_sorted,border, method=method)\n",
    "    cal_scores_sorted_bool = cal_scores_sorted >= quantile_significance\n",
    "    for i in range(len(cal_scores_sorted)):\n",
    "        if cal_scores_sorted_bool[i]:\n",
    "            number = i\n",
    "    return cal_scores_sorted[number]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8957d0c",
   "metadata": {},
   "source": [
    "### Definition of the signed error function: \n",
    "\n",
    "$\\alpha_i = y_i - \\hat{y}_i$\n",
    "\n",
    "Second function is used to form the borders for conformal regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e0918e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_error(prediction_set, y):\n",
    "    return prediction_set - y\n",
    "\n",
    "def sign_error_inv(cal_score,significance,method):\n",
    "    cal_scores_sorted = np.sort(cal_score)[::-1]\n",
    "    quantile_significance_up = np.quantile(cal_scores_sorted, significance / 2, method=method)\n",
    "    quantile_significance_low = np.quantile(cal_scores_sorted, 1 - significance / 2, method=method)\n",
    "    up_bool = np.array(cal_scores_sorted <= quantile_significance_up)\n",
    "    low_bool = np.array(cal_scores_sorted <= quantile_significance_low)\n",
    "    return -cal_scores_sorted[np.where(up_bool == True)[0][0]], cal_scores_sorted[np.where(low_bool == True)[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e61a474",
   "metadata": {},
   "source": [
    "### Applying error functions on calibration data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c40a94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_scores_abs = abserror(predictions_cal, data_target[idx_cal])\n",
    "cal_scores_sign = sign_error(predictions_cal, data_target[idx_cal])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654336d0",
   "metadata": {},
   "source": [
    "### Generating border values\n",
    "Border values helps us define upper and lower limits. So future predictions with some significance level must be in a such prediction region. This computation is based on an algorithm for finding the quantile, or a position in a sorted calibration dataset and then comparison test dataset predictions with calibration quantile.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9b5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "significance = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92d701a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_abs = np.zeros((idx_test.size, 2))\n",
    "intervals_sign = np.zeros((idx_test.size, 2))\n",
    "\n",
    "borders_abs = abs_err_inv(cal_scores_abs, significance=significance, method='weibull')\n",
    "intervals_abs[:, 0] = predictions_test - borders_abs\n",
    "intervals_abs[:, 1] = predictions_test + borders_abs\n",
    "\n",
    "borders_sign = sign_error_inv(cal_scores_sign, significance=significance, method='weibull')\n",
    "intervals_sign[:, 0] = predictions_test - borders_sign[0]\n",
    "intervals_sign[:, 1] = predictions_test + borders_sign[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86ee35",
   "metadata": {},
   "source": [
    "# Nonconformist library\n",
    "Now we will use [nonconformist library](https://github.com/donlnz/nonconformist) to show the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6df7a5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.1559041,  5.4234862],\n",
       "       [-0.4115197,  1.8560624],\n",
       "       [ 1.2780506,  3.5456327],\n",
       "       [ 0.7563003,  3.0238824],\n",
       "       [-0.5486697,  1.7189124]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_sign = NcFactory.create_nc(model, err_func=SignErrorErrFunc())\t# Create a default nonconformity function\n",
    "icp_sign = IcpRegressor(nc_sign)\t\t\t# Create an inductive conformal regressor\n",
    "\n",
    "# To avoid overfitting the model - we should comment this line \n",
    "#icp_sign.fit(data_data[idx_train, :], data_target[idx_train])\n",
    "\n",
    "# Calibrate the ICP using the calibration set\n",
    "icp_sign.calibrate(data_data[idx_cal, :], data_target[idx_cal])\n",
    "\n",
    "# Produce predictions for the test set, with confidence 95%\n",
    "prediction_sign = icp_sign.predict(data_data[idx_test, :],significance = significance)\n",
    "\n",
    "# Print first 5 predictions\n",
    "prediction_sign[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f7b400f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.2748138,  5.5725738],\n",
       "       [-0.29261  ,  2.00515  ],\n",
       "       [ 1.3969603,  3.6947203],\n",
       "       [ 0.87521  ,  3.17297  ],\n",
       "       [-0.42976  ,  1.868    ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_abs = NcFactory.create_nc(model, err_func=AbsErrorErrFunc())\t# Create a default nonconformity function\n",
    "icp_abs = IcpRegressor(nc_abs)\t\t\t# Create an inductive conformal regressor\n",
    "\n",
    "#icp_sign.fit(data_data[idx_train, :], data_target[idx_train])\n",
    "\n",
    "# Calibrate the ICP using the calibration set\n",
    "icp_abs.calibrate(data_data[idx_cal, :], data_target[idx_cal])\n",
    "\n",
    "# Produce predictions for the test set, with confidence 95%\n",
    "prediction_abs = icp_abs.predict(data_data[idx_test, :], significance = significance)\n",
    "\n",
    "# Print first 5 predictions\n",
    "prediction_abs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1967f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different predictions between noncomformist and our region\n",
      "predictor based on nonconformity values.\n",
      "Absolute error function:0\n",
      "Signed error function:0\n"
     ]
    }
   ],
   "source": [
    "sign_sum = np.sum(prediction_sign != intervals_sign)\n",
    "abs_sum = np.sum(prediction_abs != intervals_abs)\n",
    "\n",
    "print(\"Number of different predictions between noncomformist and our region\\n\\\n",
    "predictor based on nonconformity values.\\n\\\n",
    "Absolute error function:{}\\n\\\n",
    "Signed error function:{}\".format(abs_sum,sign_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31d702f",
   "metadata": {},
   "source": [
    "## Important features of error functions\n",
    "There are some features to be aware of, because they can make significant impact on the output of conformal regressor. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9375910d",
   "metadata": {},
   "source": [
    "**First:** the size of the calibration dataset. The number of points, or the size, must be a multiple of 100, because when we're taking the quantile - different number can be choosen by ***numpy.quantile()*** function.As the function for choosing quantile position in the calibration dataset and function in **nonconformist library** is different we can get various values, but they are not likely to differ very much in numerical value(in most of the cases).\n",
    "**And the method parameter** of taking the quantile in ***numpy.quantile()*** function can make adjustments [when the desired quantile lies between two data points](https://numpy.org/doc/stable/reference/generated/numpy.quantile.html).\n",
    "Below there's an example of the synthetic array, but it will be still clear how the **first feature** can affect the output of the ***numpy.quantile()*** function, comparison will be computed with the function from the **nonconformist library.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "366bff4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of first array:200,\n",
      " Size of second array:191\n",
      "Number of False values for first array:0\n",
      "Number of False values for second array:96\n"
     ]
    }
   ],
   "source": [
    "arr_mult = np.arange(0,200,1)\n",
    "arr_nonmult = np.arange(1,192,1)\n",
    "print(\"Size of first array:{},\\n Size of second array:{}\".format(len(arr_mult),len(arr_nonmult)))\n",
    "arr_sign = np.arange(0.01, 0.99, 0.01) #example for all significance levels (from 1% to 99%)\n",
    "false_vals = []\n",
    "false_vals2 = []\n",
    "for i in arr_sign:\n",
    "    quantile_arr = np.array(np.quantile(arr_mult, (1-i * ((len(arr_mult) + 1)/len(arr_mult))), method = 'inverted_cdf' ))\n",
    "    quantile_arr2 = int(np.floor((1-i) * (len(arr_mult) + 1)))-1\n",
    "    false_vals.append(quantile_arr == quantile_arr2)\n",
    "print(\"Number of False values for first array:{}\".format(np.sum(np.array(false_vals) == False)))\n",
    "\n",
    "for i in arr_sign:\n",
    "    quantile_arr1 = np.quantile(arr_nonmult, 1-i * ((len(arr_nonmult) + 1)/len(arr_nonmult)), method = 'inverted_cdf' )\n",
    "    quantile_arr21 = int(np.floor((1-i) * (len(arr_nonmult) + 1)))-1\n",
    "    false_vals2.append(quantile_arr1 == quantile_arr21)\n",
    "print(\"Number of False values for second array:{}\".format(np.sum(np.array(false_vals2) == False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f8d7f",
   "metadata": {},
   "source": [
    "**As we can see - size of the calibration set must be a multiple of 100. Otherwise - we will recieve wrong values for almost all cases.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a71dd2",
   "metadata": {},
   "source": [
    "**Second:** correction coefficient. \n",
    "Computing not just (1- *significance*) but a significance multiplied by correction coefficient, which helps us adapt to the different sizes of the dataset.\n",
    "\n",
    "$(1-significance)$\n",
    "\n",
    "$(1-significance)*(len+1)/len$ , where len is length of the calibration set\n",
    "\n",
    "However here should be noted, that *method* parameter in ***numpy.quantile()*** function can help us get right values. Below will be example of how the combination of method parameter and significance level estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "602d7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_err_inv_example(cal_score, significance,method, borders):\n",
    "    cal_scores_sorted = np.sort(cal_score)[::-1]\n",
    "    if borders==1:\n",
    "        border = 1 - significance \n",
    "    else:\n",
    "        border = (1-significance)*((len(cal_scores_sorted)+1)/len(cal_scores_sorted))\n",
    "    quantile_significance = np.quantile(cal_scores_sorted,border, method=method)\n",
    "    cal_scores_sorted_bool = cal_scores_sorted >= quantile_significance\n",
    "    for i in range(len(cal_scores_sorted)):\n",
    "        if cal_scores_sorted_bool[i]:\n",
    "            number = i\n",
    "    return cal_scores_sorted[number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fdf1d5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Significance estimation + method and number of different predictions\n",
      "\n",
      "inverted_cdf 4128\n",
      "inverted_cdf 0\n",
      "averaged_inverted_cdf 0\n",
      "averaged_inverted_cdf 0\n",
      "closest_observation 4128\n",
      "closest_observation 0\n",
      "interpolated_inverted_cdf 4128\n",
      "interpolated_inverted_cdf 0\n",
      "hazen 0\n",
      "hazen 4128\n",
      "weibull 0\n",
      "weibull 4128\n",
      "median_unbiased 0\n",
      "median_unbiased 4128\n",
      "normal_unbiased 0\n",
      "normal_unbiased 4128\n",
      "\n",
      " Average number of non-equal predictions for all methods \n",
      "and for normal significance level:1548.0\n",
      " Average number of non-equal predictions for all methods \n",
      "and for significance level multiplied by correction coefficient:2064.0\n"
     ]
    }
   ],
   "source": [
    "method_q = ['inverted_cdf','averaged_inverted_cdf','closest_observation','interpolated_inverted_cdf',\n",
    "              'hazen','weibull','median_unbiased','normal_unbiased']\n",
    "intervals_abs1 = np.zeros((idx_test.size, 2))\n",
    "intervals_abs2 = np.zeros((idx_test.size, 2))\n",
    "a = []\n",
    "b = []\n",
    "print(\"\\nSignificance estimation + method and number of different predictions\\n\")\n",
    "for i in method_q:\n",
    "    borders_abs = abs_err_inv_example(cal_scores_abs, significance=significance, method=i, borders = 1)\n",
    "    intervals_abs1[:, 0] = predictions_test - borders_abs\n",
    "    intervals_abs1[:, 1] = predictions_test + borders_abs\n",
    "    abs_sum1 = np.sum(prediction_abs != intervals_abs1)\n",
    "    #print(\"\\nNormal significance level estimation + {} \\n\\\n",
    "    #Number of different predictions:{}\".format(i,abs_sum1))\n",
    "    print(i,abs_sum1)\n",
    "    a.append(abs_sum1)\n",
    "    borders_abs2 = abs_err_inv_example(cal_scores_abs, significance=significance, method=i, borders = 2)\n",
    "    intervals_abs2[:, 0] = predictions_test - borders_abs2\n",
    "    intervals_abs2[:, 1] = predictions_test + borders_abs2\n",
    "    abs_sum2 = np.sum(prediction_abs != intervals_abs2)\n",
    "    #print(\"\\nSignificance level estimation multiplied by correction coefficient + {} \\n\\\n",
    "    #Number of different predictions:{}\".format(i,abs_sum2))\n",
    "    print(i,abs_sum2)\n",
    "    b.append(abs_sum2)\n",
    "\n",
    "print(\"\\n Average number of non-equal predictions for all methods \\n\\\n",
    "and for normal significance level:{}\\n\\\n",
    " Average number of non-equal predictions for all methods \\n\\\n",
    "and for significance level multiplied by correction coefficient:{}\".format(np.sum(a)/len(method_q),np.sum(b)/len(method_q)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
